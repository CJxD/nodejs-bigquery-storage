// Copyright 2022 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ** This file is automatically generated by gapic-generator-typescript. **
// ** https://github.com/googleapis/gapic-generator-typescript **
// ** All changes to this file may be overwritten. **

import * as gax from 'google-gax';
import * as protos from '../../protos/protos';
import * as assert from 'assert';
import * as sinon from 'sinon';
import {describe, it} from 'mocha';
import * as protobufjs from 'protobufjs';
// import {managedwriter} from '../../src';
import * as bigquerywriterModule from '../../src';
import {CustomerRecordMessage} from '../managedwriter/test_protos';
import * as customer_record from './test_protos/proto';
// import {PassThrough} from 'stream';

import {ClientOptions} from 'google-gax';

// Dynamically loaded proto JSON is needed to get the type information
// to fill in default values for request objects
/*const root = protobuf.Root.fromJSON(
  require('../../protos/protos.json')
).resolveAll();*/

type WriteStream = protos.google.cloud.bigquery.storage.v1.IWriteStream;
type ProtoData =
  protos.google.cloud.bigquery.storage.v1.AppendRowsRequest.IProtoData;
// type ProtoRows = protos.google.cloud.bigquery.storage.v1.IProtoRows;
type ProtoSchema = protos.google.cloud.bigquery.storage.v1.IProtoSchema;
type ProtoDescriptor = protos.google.protobuf.IDescriptorProto;
type IInt64Value = protos.google.protobuf.IInt64Value;
type Message = gax.protobuf.Message;
type AppendRowsResponse =
  protos.google.cloud.bigquery.storage.v1.IAppendRowsResponse;
const type = protos.google.protobuf.FieldDescriptorProto.Type;

// eslint-disable-next-line @typescript-eslint/no-unused-vars

describe('managedwriter.WriterClient', () => {
  describe('Common methods', () => {
    it('should create a client without arguments', () => {
      const projectId = 'fake-project-id';
      const datasetId = 'fake-dataset-id';
      const tableId = 'fake-table-id';
      const parent =
        'projects/fake-project-id/datasets/fake-dataset-id/tables/fake-table-id';
      const client = new bigquerywriterModule.managedwriter.WriterClient();
      client.setParent(projectId, datasetId, tableId);
      assert(client);
      assert.strictEqual(client.getParent(), parent);
      assert(client.getClient());
      assert.strictEqual(client.getWriteStreamType(), 'TYPE_UNSPECIFIED');
    });

    it('should create a client with arguments: parent, client, opts, writeStream', () => {
      const parent =
        'projects/fake-project-id/datasets/fake-dataset-id/tables/fake-table-id';
      const bqWriteClient: bigquerywriterModule.BigQueryWriteClient =
        new bigquerywriterModule.BigQueryWriteClient({
          credentials: {
            client_email: 'fake-client@email.com',
            private_key: 'fake-private-key',
          },
          projectId: 'fake-project-id',
        });
      const options: ClientOptions = {
        projectId: 'fake-project-id',
      };
      const writeStreamType: WriteStream['type'] = 'TYPE_UNSPECIFIED';
      const client = new bigquerywriterModule.managedwriter.WriterClient(
        parent,
        bqWriteClient,
        options,
        writeStreamType
      );
      assert(client);
      assert.strictEqual(client.getParent(), parent);
      assert(client.getClient());
      Promise.resolve(client.getClient().getProjectId()).then(clientId => {
        assert.strictEqual(clientId, options.projectId);
      });
      assert.strictEqual(client.getWriteStreamType(), 'TYPE_UNSPECIFIED');
    });
  });

  describe('createSerializedRows', () => {
    it('should invoke createSerializedRows without error', () => {
      // const customer_record_pb = require('../../samples/customer_record_pb.js');
      const parent =
        'projects/fake-project-id/dataset/fake-dataset-id/table/fake-table-id';
      const options: ClientOptions = {
        projectId: 'fake-project-id',
      };
      const client = new bigquerywriterModule.managedwriter.WriterClient(
        parent,
        undefined,
        options,
        undefined
      );

      type CustomerRecord = customer_record.customer_record.ICustomerRecord;
      const protoDescriptor: ProtoDescriptor = {};
      protoDescriptor.name = 'CustomerRecord';
      protoDescriptor.field = [
        {
          name: 'customer_name',
          number: 1,
          type: type.TYPE_STRING,
        },
        {
          name: 'row_num',
          number: 2,
          type: type.TYPE_INT64,
        },
      ];

      // Row 1
      const row1: CustomerRecord = {
        customerName: 'Lovelace',
        rowNum: 1,
      };
      const row1Message = new CustomerRecordMessage(
        row1.rowNum,
        row1.customerName
      ).createCustomerRecord();

      // Row 2
      const row2: CustomerRecord = {
        customerName: 'Turing',
        rowNum: 2,
      };
      const row2Message = new CustomerRecordMessage(
        row2.rowNum,
        row2.customerName
      ).createCustomerRecord();

      const schema: ProtoSchema = {
        protoDescriptor: protoDescriptor,
      };
      const rowData: Message[] = [row1Message, row2Message];
      const serializedRowData: ProtoData = {
        rows: {
          serializedRows: rowData.map(row =>
            protobufjs.Message.encode(row).finish()
          ),
        },
        writerSchema: schema,
      };

      const serializedRows = client.createSerializedRows(rowData, schema);
      assert.strictEqual(serializedRows, serializedRowData);
    });

    /*it('should invoke createSerializedRows with errors', () => {
      //test
    });*/

    /*it('should invoke createSerializedRows with closed stream and connection', () => {
      //test
      // "Stream" is finalized. Entity: projects/loferris-sandbox/datasets/writer_dataset_sandbox/tables/writer_table_sandbox/streams/CiQ2NDJiYmM0NS0wMDAwLTIyMjMtYWEyOC05NGViMmMxMzdhYmU"
    });*/
  });

  describe('initializeStreamConnection', () => {
    it('should invoke initalizeStreamConnection with or without clientOptions without errors', () => {
      const parent =
        'project/fake-project-id/dataset/fake-dataset-id/table/fake-table-id';
      const bqWriteClient: bigquerywriterModule.BigQueryWriteClient =
        new bigquerywriterModule.BigQueryWriteClient({
          credentials: {
            client_email: 'fake-client@email.com',
            private_key: 'fake-private-key',
          },
          projectId: 'fake-project-id',
        });
      bqWriteClient.initialize();
      const writeStreamType: WriteStream['type'] = 'PENDING';
      const client = new bigquerywriterModule.managedwriter.WriterClient(
        parent,
        bqWriteClient,
        undefined,
        writeStreamType
      );
      const numConnections: number =
        client.getConnections().connection_list.length;

      /*invokes initializeStreamConnection without arguments*/
      client.initializeStreamConnection().then(() => {
        const streamId = 'fake-stream-id';
        const streamIdResult = sinon.replace(
          client,
          'getStreamId',
          sinon.fake.returns(streamId)
        );
        assert(client.getConnections().connection_list.length === 1);
        assert(client.getConnections().connections['streamId']);
        assert.strictEqual(streamIdResult, streamId);
      });

      /* invokes initializeStreamConnection with CallOptions */
      const callOptions: gax.CallOptions = {};
      const streamCallOptionsId = 'fake-stream-id-with-call-options';
      client.initializeStreamConnection(callOptions).then(() => {
        const streamIdCallOptionsResult = sinon.replace(
          client,
          'getStreamId',
          sinon.fake.returns(streamCallOptionsId)
        );
        console.log(client.getConnections().connection_list.length);
        assert(
          client.getConnections().connection_list.length === numConnections + 2
        );
        assert(client.getConnections().connections['streamId']);
        assert.strictEqual(streamIdCallOptionsResult, streamCallOptionsId);
      });
    });

    /*it('should invoke initalizeStreamConnection with errors', () => {

    })
    it('should invoke initalizeStreamConnection with closed client', () => {

    })*/
  });

  describe('appendRowsToStream', () => {
    it('should invoke appendRowsToStream without errors', () => {
      const parent =
        'project/fake-project-id/dataset/fake-dataset-id/table/fake-table-id';
      const bqWriteClient: bigquerywriterModule.BigQueryWriteClient =
        new bigquerywriterModule.BigQueryWriteClient({
          credentials: {
            client_email: 'fake-client@email.com',
            private_key: 'fake-private-key',
          },
          projectId: 'fake-project-id',
        });
      bqWriteClient.initialize();
      const writeStreamType: WriteStream['type'] = 'PENDING';
      const client = new bigquerywriterModule.managedwriter.WriterClient(
        parent,
        bqWriteClient,
        undefined,
        writeStreamType
      );

      const streamId = 'fake-stream-id';

      /* serialized rowData to be appended to stream */
      type CustomerRecord = customer_record.customer_record.ICustomerRecord;
      const protoDescriptor: ProtoDescriptor = {};
      protoDescriptor.name = 'CustomerRecord';
      protoDescriptor.field = [
        {
          name: 'customer_name',
          number: 1,
          type: type.TYPE_STRING,
        },
        {
          name: 'row_num',
          number: 2,
          type: type.TYPE_INT64,
        },
      ];

      // Row 1
      const row1: CustomerRecord = {
        customerName: 'Lovelace',
        rowNum: 1,
      };
      const row1Message = new CustomerRecordMessage(
        row1.rowNum,
        row1.customerName
      ).createCustomerRecord();

      // Row 2
      const row2: CustomerRecord = {
        customerName: 'Turing',
        rowNum: 2,
      };
      const row2Message = new CustomerRecordMessage(
        row2.rowNum,
        row2.customerName
      ).createCustomerRecord();

      const schema: ProtoSchema = {
        protoDescriptor: protoDescriptor,
      };
      const rowData: Message[] = [row1Message, row2Message];
      const serializedRowData: ProtoData = {
        rows: {
          serializedRows: rowData.map(row =>
            protobufjs.Message.encode(row).finish()
          ),
        },
        writerSchema: schema,
      };

      const offset: IInt64Value = {
        value: 0,
      };

      const appendRowsResponsesResult: AppendRowsResponse[] = [
        {
          appendResult: {
            offset: offset,
          },
          writeStream: streamId,
        },
      ];
      client
        .initializeStreamConnection()
        .then(() => {
          client.appendRowsToStream(streamId, serializedRowData, offset);
        })
        .then(appendRowResponses => {
          assert.strictEqual(appendRowsResponsesResult, appendRowResponses);
          // assertions
        });
    });

    /*it('should invoke appendRowsToStream with errors', () => {

    })*/

    /*it('should invoke appendRowsToStream with closed client', () => {

    })*/
  });

  /* describe('closeStream', () => {
    it('should invoke closeStream without errors', () => {

    })

    it('should invoke closeStream with errors', () => {

    })

    it('should invoke closeStream with closed client', () => {

    })
  })*/
});
