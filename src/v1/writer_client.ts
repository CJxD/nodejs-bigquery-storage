// Copyright 2022 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ** This file is automatically generated by gapic-generator-typescript. **
// ** https://github.com/googleapis/gapic-generator-typescript **
// ** All changes to this file may be overwritten. **

/* global window */
import * as gax from 'google-gax';
import * as protobufjs from 'protobufjs';
import type {
  Callback,
  CallOptions,
  Descriptors,
  ClientOptions,
} from 'google-gax';
import {PassThrough} from 'stream';
import * as protos from '../../protos/protos';
import jsonProtos = require('../../protos/protos.json');
/**
 * Client JSON configuration object, loaded from
 * `src/v1/big_query_write_client_config.json`.
 * This file defines retry strategy and timeouts for all API methods in this library.
 */
import * as gapicConfig from './big_query_write_client_config.json';
const version = require('../../package.json').version;


import {BigQueryWriteClient} from '.';
import { write } from 'fs';
//import {createParent, writeStreams} from './helpers_sandbox';

/**
 *  BigQuery Write API.
 *
 *  The Write API can be used to write data to BigQuery.
 *
 *  For supplementary information about the Write API, see:
 *  https://cloud.google.com/bigquery/docs/write-api
 * @class
 * @memberof v1
 */


// type StreamType = protos.google.cloud.bigquery.storage.v1.WriteStream;
type WriteStream = protos.google.cloud.bigquery.storage.v1.IWriteStream;
type AppendRowResponse =
  protos.google.cloud.bigquery.storage.v1.AppendRowsResponse;
type AppendRowRequest = protos.google.cloud.bigquery.storage.v1.IAppendRowsRequest;
type IInt64Value = protos.google.protobuf.IInt64Value;
type ProtoData = protos.google.cloud.bigquery.storage.v1.AppendRowsRequest.IProtoData;
type ProtoRows = protos.google.cloud.bigquery.storage.v1.IProtoRows;
type ProtoSchema = protos.google.cloud.bigquery.storage.v1.IProtoSchema;
type ProtoDescriptor = protos.google.protobuf.IDescriptorProto;
type Message = gax.protobuf.Message;

export class WriterClient {
  private _terminated = false;
  private _opts: ClientOptions;
  private _providedCustomServicePath: boolean;
  private _gaxModule: typeof gax | typeof gax.fallback;
  private _gaxGrpc: gax.GrpcClient | gax.fallback.GrpcClient;
  private _protos: {};
  private _defaults: {[method: string]: gax.CallSettings};
  auth: gax.GoogleAuth;
  descriptors: Descriptors = {
    page: {},
    stream: {},
    longrunning: {},
    batching: {},
  };
  warn: (code: string, message: string, warnType?: string) => void;
  innerApiCalls: {[name: string]: Function};
  pathTemplates: {[name: string]: gax.PathTemplate};
  private _parent: string;
  private _projectId: string = "Please specify project_id";
  private _datasetId: string = "Please specify dataset_id";
  //change hardcoding
  private _writeStream: WriteStream = {type: "PENDING"};
  private _streamId: string;
  // private _parent = 'projects/myProjectId/datasets/myDatasetId/tables/myTableId';
  writerStub?: Promise<{[name: string]: Function}>;
  bigQueryClient: BigQueryWriteClient

  constructor(parent: string, opts: ClientOptions, writeStream?: WriteStream, gaxInstance?: typeof gax | typeof gax.fallback
    ) {
    this._parent = parent;
    this._projectId = opts.projectId || projectId;
    this._datasetId = datasetId;
    this.bigQueryClient = new BigQueryWriteClient(opts);
    this._writeStream = writeStream || this._writeStream;
    this._streamId = 'Please open a connection to set connection name';
    // Ensure that options include all the required fields.
    const staticMembers = this.constructor as typeof WriterClient;
    const servicePath =
      opts?.servicePath || opts?.apiEndpoint || staticMembers.servicePath;
    this._providedCustomServicePath = !!(
      opts?.servicePath || opts?.apiEndpoint
    );
    const port = opts?.port || staticMembers.port;
    const clientConfig = opts?.clientConfig ?? {};
    const fallback =
      opts?.fallback ??
      (typeof window !== 'undefined' && typeof window?.fetch === 'function');
    opts = Object.assign({servicePath, port, clientConfig, fallback}, opts);

    // If scopes are unset in options and we're connecting to a non-default endpoint, set scopes just in case.
    if (servicePath !== staticMembers.servicePath && !('scopes' in opts)) {
      opts['scopes'] = staticMembers.scopes;
    }

    // Load google-gax module synchronously if needed
    if (!gaxInstance) {
      gaxInstance = require('google-gax') as typeof gax;
    }

    // Choose either gRPC or proto-over-HTTP implementation of google-gax.
    this._gaxModule = opts.fallback ? gaxInstance.fallback : gaxInstance;

    // Create a `gaxGrpc` object, with any grpc-specific options sent to the client.
    this._gaxGrpc = new this._gaxModule.GrpcClient(opts);

    // Save options to use in initialize() method.
    this._opts = opts;

    // Save the auth object to the client, for use by other methods.
    this.auth = this._gaxGrpc.auth as gax.GoogleAuth;

    // Set useJWTAccessWithScope on the auth object.
    this.auth.useJWTAccessWithScope = true;

    // Set defaultServicePath on the auth object.
    this.auth.defaultServicePath = staticMembers.servicePath;

    // Set the default scopes in auth client if needed.
    if (servicePath === staticMembers.servicePath) {
      this.auth.defaultScopes = staticMembers.scopes;
    }

    // Determine the client header string.
    const clientHeader = [`gax/${this._gaxModule.version}`, `gapic/${version}`];
    if (typeof process !== 'undefined' && 'versions' in process) {
      clientHeader.push(`gl-node/${process.versions.node}`);
    } else {
      clientHeader.push(`gl-web/${this._gaxModule.version}`);
    }
    if (!opts.fallback) {
      clientHeader.push(`grpc/${this._gaxGrpc.grpcVersion}`);
    } else if (opts.fallback === 'rest') {
      clientHeader.push(`rest/${this._gaxGrpc.grpcVersion}`);
    }
    if (opts.libName && opts.libVersion) {
      clientHeader.push(`${opts.libName}/${opts.libVersion}`);
    }
    // Load the applicable protos.
    this._protos = this._gaxGrpc.loadProtoJSON(jsonProtos);

    // This API contains "path templates"; forward-slash-separated
    // identifiers to uniquely identify resources within the API.
    // Create useful helper objects for these.
    this.pathTemplates = {
      projectPathTemplate: new this._gaxModule.PathTemplate(
        'projects/{project}'
      ),
      readSessionPathTemplate: new this._gaxModule.PathTemplate(
        'projects/{project}/locations/{location}/sessions/{session}'
      ),
      readStreamPathTemplate: new this._gaxModule.PathTemplate(
        'projects/{project}/locations/{location}/sessions/{session}/streams/{stream}'
      ),
      tablePathTemplate: new this._gaxModule.PathTemplate(
        'projects/{project}/datasets/{dataset}/tables/{table}'
      ),
      writeStreamPathTemplate: new this._gaxModule.PathTemplate(
        'projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}'
      ),
    };

    // Some of the methods on this service provide streaming responses.
    // Provide descriptors for these.
    this.descriptors.stream = {
      appendRows: new this._gaxModule.StreamDescriptor(
        this._gaxModule.StreamType.BIDI_STREAMING,
        opts.fallback === 'rest'
      ),
    };

    // Put together the default options sent with requests.
    this._defaults = this._gaxGrpc.constructSettings(
      'google.cloud.bigquery.storage.v1.BigQueryWrite',
      gapicConfig as gax.ClientConfig,
      opts.clientConfig || {},
      {'x-goog-api-client': clientHeader.join(' ')}
    );

    // Set up a dictionary of "inner API calls"; the core implementation
    // of calling the API is handled in `google-gax`, with this code
    // merely providing the destination and request information.
    this.innerApiCalls = {};

    // Add a warn function to the client constructor so it can be easily tested.
    this.warn = this._gaxModule.warn;
  
  }

  /**
   * Initialize the client.
   * Performs asynchronous operations (such as authentication) and prepares the client.
   * This function will be called automatically when any class method is called for the
   * first time, but if you need to initialize it before calling an actual method,
   * feel free to call initialize() directly.
   *
   * You can await on this method if you want to make sure the client is initialized.
   *
   * @returns {Promise} A promise that resolves to an authenticated service stub.
   */
  initialize() {
    // If the client stub promise is already initialized, return immediately.
    if (this.writerStub) {
      return this.writerStub;
    }

    // Put together the "service stub" for
    // google.cloud.bigquery.storage.v1.BigQueryWrite.
    this.writerStub = this._gaxGrpc.createStub(
      this._opts.fallback
        ? (this._protos as protobuf.Root).lookupService(
            'google.cloud.bigquery.storage.v1.WriterClient'
          )
        : // eslint-disable-next-line @typescript-eslint/no-explicit-any
          (this._protos as any).google.cloud.bigquery.storage.v1.WriterClient,
      this._opts,
      this._providedCustomServicePath
    ) as Promise<{[method: string]: Function}>;

    // Iterate over each of the methods that the service provides
    // and create an API call method for each.
    const writerStubMethods = [
      'setParent',
      'getParent',
      'createSerializedRows',
      'getWriteStreams',
      'setWriteStream',
      'initializeWriteStream',
      'appendRowsToStream',
      'closeStream'
    ];
    for (const methodName of writerStubMethods) {
      const callPromise = this.writerStub.then(
        stub =>
          (...args: Array<{}>) => {
            if (this._terminated) {
              if (methodName in this.descriptors.stream) {
                const stream = new PassThrough();
                setImmediate(() => {
                  stream.emit(
                    'error',
                    new this._gaxModule.GoogleError(
                      'The client has already been closed.'
                    )
                  );
                });
                return stream;
              }
              return Promise.reject('The client has already been closed.');
            }
            const func = stub[methodName];
            return func.apply(stub, args);
          },
        (err: Error | null | undefined) => () => {
          throw err;
        }
      );

      const descriptor = this.descriptors.stream[methodName] || undefined;
      const apiCall = this._gaxModule.createApiCall(
        callPromise,
        this._defaults[methodName],
        descriptor,
        this._opts.fallback
      );

      this.innerApiCalls[methodName] = apiCall;
    }

    return this.writerStub;
  }
  
  /**
   * The DNS address for this API service.
   * @returns {string} The DNS address for this service.
   */
   static get servicePath() {
    return 'bigquerystorage.googleapis.com';
  }

  /**
   * The DNS address for this API service - same as servicePath(),
   * exists for compatibility reasons.
   * @returns {string} The DNS address for this service.
   */
  static get apiEndpoint() {
    return 'bigquerystorage.googleapis.com';
  }

  /**
   * The port for this API service.
   * @returns {number} The default port for this service.
   */
  static get port() {
    return 443;
  }

  /**
   * The scopes needed to make gRPC calls for every method defined
   * in this service.
   * @returns {string[]} List of default scopes.
   */
  static get scopes() {
    return [
      'https://www.googleapis.com/auth/bigquery',
      'https://www.googleapis.com/auth/bigquery.insertdata',
      'https://www.googleapis.com/auth/cloud-platform',
    ];
  }

  getProjectId(): Promise<string>;
  getProjectId(callback: Callback<string, undefined, undefined>): void;
  /**
   * Return the project ID used by this class.
   * @returns {Promise} A promise that resolves to string containing the project ID.
   */
  getProjectId(
    callback?: Callback<string, undefined, undefined>
  ): Promise<string> | void {
    if (callback) {
      this.auth.getProjectId(callback);
      return;
    }
    return this.auth.getProjectId();
  }

  setParent = (projectId: string, datasetId: string, tableId: string): void => {
    const parent = `projects/${projectId}/datasets/${datasetId}/tables/${tableId}`;
    this._parent = parent;
  };
  
  getParent = (): string =>{
    return this._parent
  }

  setDatasetId = (datasetId: string): void => {
    this._datasetId = datasetId;
  }

  getDatasetId = (): string => {
    return this._datasetId;
  }

  getStreamId = (): string => {
    return this._streamId;
  }

  createSerializedRows = (rowData: Message[], schema?: ProtoSchema): ProtoData => {
    const serializedRows: ProtoRows = {
      serializedRows: []
    };
    const convertedRows: Uint8Array[] = []
    rowData.forEach(entry => {
      convertedRows.push(protobufjs.Message.encode(entry).finish());
    })
      /*let message = new protobufjs.Message({
        properties: entry
      });*/
      /*let entryMessage: gax.protobuf.Message;

      if (entry != undefined) {
        entryMessage = protobufjs.Message.create(entry);
        const errorMessage = "Invalid: row must be a valid object"
        const err: string | null = protobufjs.Message.verify(entryMessage);
        if (err) {
          throw new Error(errorMessage);
         } else {
          convertedRows.push(protobufjs.Message.encode(entryMessage).finish());
        }
      } else {
        throw new Error('Rows cannot be undefined')
      }
    });*/
    serializedRows.serializedRows = convertedRows;
    //fix writerSchema thing
    const protoDescriptor: ProtoDescriptor = {}
    const writerSchema: ProtoSchema = schema || {
      protoDescriptor: protoDescriptor
    }
    const serializedRowData: ProtoData = {
      rows: serializedRows,
      writerSchema: writerSchema
    }
    return serializedRowData;
  };

  getWriteStreams = (writeStream: WriteStream): undefined | null | string[] => {
    if (writeStream === undefined || writeStream.name === undefined) {
      return undefined;
    }
    if (writeStream.name === null) {
      return null;
    }
    return new Array(writeStream.name);
  };

  setWriteStream(streamType: WriteStream): void {
    /**let writeStream: WriteStream;
    if (streamType) {
      writeStream = {type: streamType.type};
    }
    writeStream = {type: "TYPE_UNSPECIFIED"};
    return writeStream;**/
    this._writeStream = {type: streamType.type};
  }

  getWriteStream(): WriteStream {
    return this._writeStream
  }

  async initializeStreamConnection(
    clientOptions?: CallOptions,
  ): Promise<gax.CancellableStream> {
    const bqWriteClient: BigQueryWriteClient = this.bigQueryClient;
    const request: protos.google.cloud.bigquery.storage.v1.ICreateWriteStreamRequest = {
      parent: this.getParent(),
      writeStream: this.getWriteStream(),
    };
    console.log(`This is the initializeStreamConnection request: ${request}`);
    const [response] = await bqWriteClient.createWriteStream(request);
    // console.log([response]);
    if (![response]) {
      throw new gax.GoogleError(`${response}`);
    }
    console.log(`Stream connection created: ${response.name}`);
    try {
      if (response.name) {
        this._streamId = response.name;
        console.log("This is the response name and what was set as streamId")
        console.log(response.name);
        console.log(this._streamId)
      }
    } catch {
      throw new Error('Stream connection failed')
    }
    if (clientOptions) {
      return this.bigQueryClient.appendRows(clientOptions);
    }
    return this.bigQueryClient.appendRows();
  }

  async appendRowsToStream(
  // set streamId correctly, write_stream for the API is a string. Options are what was set in the initializing of the connection or _default.
    connection: gax.CancellableStream,
    serializedRows: ProtoData,
    offsetValue: IInt64Value,
  ): Promise<AppendRowResponse[]> {
    const responses: AppendRowResponse[] | null = [];
    //get connection name
    const writeStream: string = this.getStreamId();
    console.log(`This is the write_stream string we're using: ${writeStream}`);

    const request: AppendRowRequest = {
      writeStream: writeStream,
      protoRows: serializedRows,
      offset: offsetValue,
    };
    
      connection.write(request, () => {
        console.log("Write complete!")
        connection.on('data', (response) => {
          // Check for errors.
          if (response.error) {
            throw new Error(response.error.message);
          }
    
          console.log(`This is the response we're getting over the wire from an appendRows request: ${response}`);
          responses.push(response);
          console.log(...responses);
          console.log(responses.length);

          if (responses.length === 1) {
            connection.end(() => {
              console.log(...responses)
              this.closeStream();
              console.log("The connection has ended.");
            });
          }
        })
          // Close the stream when all responses have been received.
        
        
        
        
      
          
    
        connection.on('error', err => {
          throw err;
        });
        })
        return responses;
    } 
    
  
  async closeStream(): Promise<void> {
    const writer: BigQueryWriteClient = this.bigQueryClient;
    // API call completed.
    const writeStream = this._streamId;
    console.log(`This is the writeStream we've stored and will be committing ${writeStream}`);
    const writeStreams: string[] | null = [];
    writeStreams.push(writeStream);
    console.log(`This is the array of writeStreams we're committing ${writeStreams}`);

    const finalizeStreamReq: protos.google.cloud.bigquery.storage.v1.IFinalizeWriteStreamRequest = {
      name: writeStream,
    }
    console.log(`This is the FinalizeWriteStreamRequest object: ${finalizeStreamReq}`);
    writer
      .finalizeWriteStream(finalizeStreamReq)
      .then(result => {
        if (!result.includes(undefined)) {
          const [validResponse] = result;
          console.log(`Row count: ${validResponse.rowCount}`);
        }
      });
    const batchCommitWriteStreamsReq: protos.google.cloud.bigquery.storage.v1.IBatchCommitWriteStreamsRequest = {
      parent: this._parent,
      writeStreams: writeStreams
    };
    console.log(`This is the BatchCommitWriteStreamsRequest object we're sending: ${batchCommitWriteStreamsReq}`)
    writer.batchCommitWriteStreams(batchCommitWriteStreamsReq).then(result => console.log(result));
  }
}

//Example
// console.log(WriterClient);
const type = protos.google.protobuf.FieldDescriptorProto.Type;
const customer_record_pb = require('./../../samples/customer_record_pb.js');
const projectId = 'your-project';
const datasetId = 'your-dataset';
const tableId = 'your-table';
const exOpts: ClientOptions = {
  projectId: projectId,
}
const exParent = `projects/${projectId}/datasets/${datasetId}/tables/${tableId}`
const writer = new WriterClient(exParent, exOpts);
//writer.setParent(projectId, datasetId, tableId);
writer.setDatasetId(datasetId);
// console.log(writer.getParent());
// console.log(writer.getDatasetId());
const streamType: WriteStream = {
  type: "PENDING"
};
writer.setWriteStream(streamType);
// console.log(writer.getWriteStream);
const writeStreamConnection: Promise<gax.CancellableStream> = writer.initializeStreamConnection();
//console.log(writer.getStreamId());
//console.log(writeStreamConnection);
/* const options: CallOptions = {};
     options.otherArgs = {};
     options.otherArgs.headers = {};
     options.otherArgs.headers[
       'x-goog-request-params'
     ] = `write_stream=${writeStream}`;*/
// options not needed for veneer

const protoDescriptorEx: ProtoDescriptor = {};
protoDescriptorEx.name = 'CustomerRecord';
protoDescriptorEx.field = [
  {
    name: 'customer_name',
    number: 1,
    type: type.TYPE_STRING,
  },
  {
    name: 'row_num',
    number: 2,
    type: type.TYPE_INT64
  }
    ];

/*type CustomerRecord = {
  row_num?: IInt64Value,
  customer_name?: string
}*/
// Row 1
let row1Message = new customer_record_pb.CustomerRecord();
row1Message.row_num = 1
row1Message.setCustomerName("Octavia")
/*let row1: CustomerRecord = {
  row_num: {
    value: 1
  },
  customer_name: "Octavia"
};*/
// console.log(row1);
// row1Message = protobufjs.Message.fromObject(row1);
// console.log(row1Message);
/*let row1 = protobufjs.Message.create({
  "row_num": {
    "value": 1
  },
  "customer_name": "Octavia"
})
console.log(row1)*/

// Row 2
let row2Message = new customer_record_pb.CustomerRecord();
row2Message.row_num = 2;
row2Message.setCustomerName("Turing");
/*let row2: CustomerRecord = {
  row_num: {
    value: 2
  },
  customer_name: "Turing"
}
console.log(row2);
let row2Message = protobufjs.Message.fromObject(row2);*/
// console.log(row2Message);
/*let row2 = protobufjs.Message.create({
  "row_num": {
    "value": 2
  },
  "customer_name": "Turing"
})
console.log(row2)*/

/*
const protoDescriptor: ProtoDescriptor = {}
    const writerSchema: ProtoSchema = schema || {
      protoDescriptor: protoDescriptor
    }
    const serializedRowData: ProtoData = {
      rows: serializedRows,
      writerSchema: writerSchema
    }
  */

const writerSchemaEx: ProtoSchema = {
  protoDescriptor: protoDescriptorEx
}
const serializedRowsEx: ProtoRows = {
  serializedRows: [row1Message.serializeBinary(), row2Message.serializeBinary()]
}

const rowData: ProtoData = {
  rows: serializedRowsEx,
  writerSchema: writerSchemaEx
}
console.log(`This is the length of the rows: ${rowData.rows?.serializedRows?.length}`)

//const rowData = [row1Message.serializeBinary(), row2Message.serializeBinary()]
// console.log(rowData);
     
// const serializedRowData = writer.createSerializedRows(rowData)
// console.log(serializedRowData)
const offset: IInt64Value = {
  value: 0
}
writeStreamConnection.then(res => {
  writer.appendRowsToStream(res, rowData, offset).then(res => {
    console.log(`AppendRowsToStream has resolved: ${res}`);
  });
})/*.then(() => {
  writer.closeStream().then(res => {
    console.log(`Close stream has been resolved: ${res}`)
  })
});*/
//WILO: 'Invalid BigQuery dataset name . Non empty project_id and dataset_id are required',